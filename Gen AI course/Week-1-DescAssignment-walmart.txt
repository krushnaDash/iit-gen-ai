------------------------------------------------------------------------------------------


COURSE: Advanced AI
TOPIC: Evolution of AI & Introduction to Transformer Models
DUE-DATE: 19 Jan 2025


INSTRUCTIONS:
1. Do not modify any tag in this file. Just type your answers in the designated place.
2. Do not change the file name and/or extension.
3. Upload this file after answering in the portal.


------------------------------------------------------------------------------------------


<<< QUESTION 1 >>>


What is Turing test? How is it performed? 


### WRITE ANSWER BELOW ###

A test to identify if a machine can think like a human. It is all started by Alan Turing during 1950, 
with two basic question can machine think? if  so how should you tell ?

It is performed by a human interrogator who is separated from both the human and the machine, in 3 seprated Room.
The interrogator will not have any idea about the participant is human or machine.

The interrogator asks questions and receives responses from both participants. 
The interrogator tries to determine which participant is the machine and which is the human.

If the interrogator cannot distinguish the machine from the human, the machine achive intelligence 
and the machine is said to have passed the Turing Test.



<<< QUESTION 2 >>>


What is an expert system? Explain its characteristics and objectives.


### WRITE ANSWER BELOW ###
It is computer program with a set of rules in the form if, else and then for solving a particular problem. 
These systems emulates decison making ability like a human expert for that domain.

Characteristics
-> Preserve the expertise from human expert
-> Can be used by non-expert users
-> Can be updated with new knowledge and rules as the domain evolves

Objective of expert system
-> To transfer the expertise from human expert to a computer system.
-> Then on to non-expert, use the computer system to take decsion like human expertise


<<< QUESTION 3 >>>


Why do modern generative models sometimes produce hallucinations?


### WRITE ANSWER BELOW ###
Its hallccinate a particular thing and take decision based on that, which generate a false output.
This is because the models are not given the context of the data they are generating.
There are some other serval reason like traning data limitations, statistical pattern Learning, context windown limitations
biasness in data.


<<< QUESTION 4 >>>


What are the building blocks of encoder in transformer and what roles do they play? 


### WRITE ANSWER BELOW ###

The encoder in transformer is made up of 6 identical blocks, like the same layer repeated 6 times as per the original paper.
Each block has three main components excluding embedding: Multi-head attention, Feed forward network and  Add and normalize.

Embedding: 
-> Converts the input tokens to dense vector representation
-> Maps the discrete token to continuous vector
-> Enables modles to work with numerical representation of text

Multi-head attention: 
    ->It is the application of self attention mechanism on the input token multiple time 
    to generate various kind of representation.
Self Attention
    ->Each self attention produce the output vector
    ->For each vector the self attention generte different Queries, Key and Value vector
    ->Then compute the attention(Q,K,V)= softmax(QK^T/SQRT(dk))V, which is nothing 
    but to contextual dependencies and relationships between all tokens regardless of distance

Feed forward network: 
    -> Each layer is fully connected to the next layer
    -> A position-wise fully connected network applied to each position independently.
    -> It is used to transform the input data into a higher-dimensional space.
    -> Adds non-linearity and transforms the representations, allowing the model to learn complex patterns.

Add and normalize
    -> It takes the embedding vector and add it to the output of the feed forward network 
    Then it normalizes the result
    -> It adds the original data along with fine tune vector to reduce the noise
So the Add operation is for adding the original data and normalize os for normalize data.


<<< QUESTION 5 >>>


Explain multi-head attention and its advantages over single-head attention.


### WRITE ANSWER BELOW ###
Multi-head attention: 
    ->It is the application of self attention mechanism on the input token multiple time 
    to generate various kind of representation.
Self Attention
    ->Each self attention produce the output vector
    ->For each vector of the self attention generte different Queries, Key and Value vector
    ->Then compute the attention(Q,K,V)= softmax(QK^T/SQRT(dk))V, which is nothing 
    but to contextual dependencies and relationships between all tokens regardless of distance
The advantages of Mutli-head attention over a single-head attention are
Multiple representation
    -> Each head capture different aspect of the input
    -> Single-head attention is limited to one type of aspect
Richer Feature learning
    -> Differnt head can focus on differn aspect and capture 
    diverse linguistic patterns simultaneously
    -> This allows the model to capture different patterns and relationships


<<< QUESTION 6 >>>


What is self-attention? Explain how does it work using Query, Key, and Value. 


### WRITE ANSWER BELOW ###

Self attention is a mechanism that allows each element in a sequence to attend all other 
elements in the same sequence, computing a weighted representation based on relevence.

->For each vector of the self attention generte different Queries, Key and Value vector
 For each input token embedding (x), compute:
  Q = x × W_Q
  K = x × W_K  
  V = x × W_V
- W_Q, W_K, W_V are learned weight matrices.

->Then compute the attention(Q,K,V)= softmax(QK^T/SQRT(dk))V, which is nothing 
    but to contextual dependencies and relationships between all tokens regardless of distance
