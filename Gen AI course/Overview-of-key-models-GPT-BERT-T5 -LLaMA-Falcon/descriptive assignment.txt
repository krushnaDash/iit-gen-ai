------------------------------------------------------------------------------------------


COURSE: Advanced AI
TOPIC: Overview of key models: GPT, BERT,T5, LLaMA, Falcon.
DUE-DATE: 25 Jan 2025


INSTRUCTIONS:
1. Do not modify any tag in this file. Just type your answers in the designated place.
2. Do not change the file name and/or extension.
3. Upload this file after answering in the portal.


------------------------------------------------------------------------------------------


<<< QUESTION 1 >>>


What is the additional number of parameters that you will need apart from the pretrained weights in the following scenarios? (a) Text classification (3 classes) using BERT-base, (b) Text Summarization using T5.


### WRITE ANSWER BELOW ###






<<< QUESTION 2 >>>


Consider a task where you would have a paragraph and a question as input, and you need to generate the answer. Which pretrained model would you use among BERT, GPT and T5? What are the advantages and disadvantages of the allowed architectures in terms of (a) number of parameters to be fine-tuned and (b) representation capacity in the context of this problem?  Can you think of a method that can take advantage of each of the allowed architectures? [Assume that all these models have the same model dimension and number of layers]


### WRITE ANSWER BELOW ###






<<< QUESTION 3 >>>


Show that the self-attention score in the rotatory embeddings depends on the positional difference between the query and key.


### WRITE ANSWER BELOW ###